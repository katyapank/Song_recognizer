{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os # библиотека для работы с файлами\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display as ld\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка всех файлов директории, создание датафрейма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение характеристик из файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 8195\n",
    "sr = 22050\n",
    "hop_length = n_fft // 2\n",
    "\n",
    "def spectrum_feature(signal):\n",
    "    ft = np.abs(librosa.stft(signal[:n_fft], n_fft=n_fft, hop_length=hop_length))\n",
    "    mean_ft = np.mean(ft, axis=1)  # Усредняем по всем каналам\n",
    "\n",
    "    return np.mean(mean_ft), np.var(mean_ft)\n",
    "\n",
    "def db_spectrum_feature(signal):\n",
    "    X = librosa.stft(signal)\n",
    "    s = librosa.amplitude_to_db(abs(X))\n",
    "\n",
    "    return np.mean(s), np.var(s)\n",
    "\n",
    "def melspectrum_feature(signal):\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc = 40, hop_length=512)\n",
    "\n",
    "    return np.mean(mfccs), np.var(mfccs)\n",
    "\n",
    "def db_melspectrum_feature(signal):\n",
    "    melspectrum = librosa.feature.melspectrogram(y=signal, sr=sr, hop_length=512, n_mels=40)\n",
    "    melspectrum_db = librosa.power_to_db(melspectrum, ref=np.max)  # Преобразуем в децибелы\n",
    "\n",
    "    return np.mean(melspectrum_db), np.var(melspectrum_db)\n",
    "\n",
    "def spectral_cent_feature(signal):\n",
    "    cent = librosa.feature.spectral_centroid(y=signal, sr=sr)\n",
    "\n",
    "    return np.mean(cent), np.var(cent)\n",
    "\n",
    "def spectral_rolloff_feature(signal):\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=signal, sr=sr)\n",
    "\n",
    "    return np.mean(rolloff), np.var(rolloff)\n",
    "\n",
    "def zero_crossing_feature(signal):\n",
    "    zrate=librosa.feature.zero_crossing_rate(signal)\n",
    "\n",
    "    return np.mean(zrate), np.var(zrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение MFCC по группам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления мел-кепстральных коэффициентов\n",
    "def compute_mfcc(audio, sr=22050, n_mfcc=13):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfccs\n",
    "\n",
    "# Функция для разбиения аудио на фрагменты по 20 секунд\n",
    "def split_audio(audio, sr=22050, fragment_length=20):\n",
    "    fragment_samples = fragment_length * sr\n",
    "    num_fragments = len(audio) // fragment_samples\n",
    "    fragments = [audio[i*fragment_samples:(i+1)*fragment_samples] for i in range(num_fragments)]\n",
    "    return fragments\n",
    "\n",
    "# Функция для разбиения мел-кепстральных коэффициентов на группы по 20 элементов\n",
    "def split_mfcc(mfccs, group_size=20):\n",
    "    num_frames = mfccs.shape[1]\n",
    "    num_groups = num_frames // group_size\n",
    "    mfcc_groups = [mfccs[:, i*group_size:(i+1)*group_size] for i in range(num_groups)]\n",
    "    return mfcc_groups\n",
    "\n",
    "# Функция для обработки отдельного аудиофайла\n",
    "def process_audio(file_path, max_duration, fragment_length=20, group_size=20):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=None, duration=max_duration)\n",
    "        audio_length = librosa.get_duration(y=audio, sr=sr)\n",
    "        if audio_length < fragment_length:\n",
    "            return None\n",
    "        fragments = split_audio(audio, sr, fragment_length)\n",
    "        data = []\n",
    "        filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        for i, fragment in enumerate(fragments):\n",
    "            mfccs = compute_mfcc(fragment, sr)\n",
    "            mfcc_groups = split_mfcc(mfccs, group_size)\n",
    "            fragment_data = {'filename': f\"{filename}_{i+1}\"}\n",
    "            for j, group in enumerate(mfcc_groups):\n",
    "                mean = np.mean(group, axis=1)\n",
    "                std_dev = np.std(group, axis=1)\n",
    "                for k in range(mean.shape[0]):\n",
    "                    fragment_data[f'MFCC_Mean_{(j*group_size)+k+1}'] = mean[k]\n",
    "                    fragment_data[f'MFCC_StdDev_{(j*group_size)+k+1}'] = std_dev[k]\n",
    "            data.append(fragment_data)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Функция для обработки всех аудиофайлов в директории\n",
    "def process_directory(directory_path, fragment_length=20, group_size=20, max_duration=60):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.mp3'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            result = process_audio(file_path, max_duration, fragment_length, group_size)\n",
    "            if result is not None:\n",
    "                data.extend(result)\n",
    "    return data\n",
    "\n",
    "# Путь к директории с аудиофайлами\n",
    "directory_path = 'songs'\n",
    "# Обработка всех аудиофайлов в директории\n",
    "data = process_directory(directory_path)\n",
    "\n",
    "csv_path = 'songs_features.csv'\n",
    "\n",
    "try:\n",
    "    with open(csv_path, 'w') as file:\n",
    "        file.truncate(0)\n",
    "    print(f\"Файл '{csv_path}' очищен успешно.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при очистке файла '{csv_path}': {e}\")\n",
    "\n",
    "# Создание датафрейма из полученных данных\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Вывод датафрейма\n",
    "print(df)\n",
    "csv_path = 'songs_features.csv'\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл 'songs_features.csv' очищен успешно.\n",
      "                                        filename  MFCC_Mean_1  MFCC_StdDev_1  \\\n",
      "0    7 Seconds -- Youssou N'Dour, Neneh Cherry_1  -220.852127     114.887589   \n",
      "1    7 Seconds -- Youssou N'Dour, Neneh Cherry_2  -177.186890      53.960754   \n",
      "2    7 Seconds -- Youssou N'Dour, Neneh Cherry_3  -175.859924      55.398659   \n",
      "3    7 Seconds -- Youssou N'Dour, Neneh Cherry_4  -168.870377      55.242714   \n",
      "4    7 Seconds -- Youssou N'Dour, Neneh Cherry_5  -158.136078      53.203526   \n",
      "..                                           ...          ...            ...   \n",
      "121              Bag Raiders -- Shooting stars_5  -153.237335      99.889580   \n",
      "122              Bag Raiders -- Shooting stars_6  -112.452782      53.073341   \n",
      "123              Bag Raiders -- Shooting stars_7  -105.967949      51.869789   \n",
      "124              Bag Raiders -- Shooting stars_8   -99.754913      50.877182   \n",
      "125              Bag Raiders -- Shooting stars_9   -92.138924      49.087082   \n",
      "\n",
      "     MFCC_Mean_2  MFCC_StdDev_2  MFCC_Mean_3  MFCC_StdDev_3  MFCC_Mean_4  \\\n",
      "0     127.102730      43.040508    -8.352807      28.400259    49.500000   \n",
      "1     141.070709      30.124899    -2.857252      16.723289    51.729279   \n",
      "2     142.481461      31.485121    -5.452794      17.106672    54.204720   \n",
      "3     140.698242      30.286985    -5.928559      17.233326    54.209587   \n",
      "4     136.648621      29.569929    -5.854443      17.531874    54.952309   \n",
      "..           ...            ...          ...            ...          ...   \n",
      "121   131.101425      42.562866   -19.374846      25.356380    46.994068   \n",
      "122   144.731018      31.210810   -26.030531      21.353319    48.927719   \n",
      "123   145.878830      31.456564   -26.110855      20.402897    49.268799   \n",
      "124   147.280884      31.200481   -25.592222      19.965687    49.558418   \n",
      "125   147.557236      31.178919   -27.464697      19.236523    49.447048   \n",
      "\n",
      "     MFCC_StdDev_4  MFCC_Mean_5  ...  MFCC_Mean_9  MFCC_StdDev_9  \\\n",
      "0        19.258394    -2.070084  ...    -7.389504       8.328297   \n",
      "1        11.961886    -3.522262  ...    -6.193279       7.928044   \n",
      "2        12.530100    -3.957153  ...    -6.299252       8.296001   \n",
      "3        12.936077    -5.074914  ...    -5.795966       8.874786   \n",
      "4        13.563373    -7.205549  ...    -4.900033      10.028434   \n",
      "..             ...          ...  ...          ...            ...   \n",
      "121      22.377243     1.047854  ...    -3.782279       8.728231   \n",
      "122      20.815315     2.706028  ...    -2.924037       8.807254   \n",
      "123      20.055653     0.811259  ...    -3.202552       9.124505   \n",
      "124      19.067041    -0.258855  ...    -2.522808       9.169756   \n",
      "125      18.726534    -4.309472  ...    -3.373760       9.297801   \n",
      "\n",
      "     MFCC_Mean_10  MFCC_StdDev_10  MFCC_Mean_11  MFCC_StdDev_11  MFCC_Mean_12  \\\n",
      "0        6.605930       13.516421     -2.262996        9.886468      5.826931   \n",
      "1       11.121572        8.926885     -0.884090        9.868897      8.073796   \n",
      "2       11.453906        9.105299     -1.590528       10.299069      8.603446   \n",
      "3       11.101801        9.165461     -3.679901       11.097007      9.589622   \n",
      "4       10.879565        9.207662     -6.115540       10.927433     10.907071   \n",
      "..            ...             ...           ...             ...           ...   \n",
      "121      7.506709       10.304597     -6.862136        8.937430      2.602234   \n",
      "122      6.481345       10.532153     -4.598908        8.058607      6.501241   \n",
      "123      5.917727       10.829220     -4.588836        8.002669      6.298923   \n",
      "124      5.079385       11.018326     -4.769823        8.123917      5.731395   \n",
      "125      4.592327       11.374182     -5.006100        8.362795      5.478089   \n",
      "\n",
      "     MFCC_StdDev_12  MFCC_Mean_13  MFCC_StdDev_13  \n",
      "0          8.361840      2.596639        6.321270  \n",
      "1          7.189212      3.526489        6.253897  \n",
      "2          7.199819      3.288556        6.551465  \n",
      "3          7.566499      2.998275        6.482382  \n",
      "4          7.684250      2.425473        6.401268  \n",
      "..              ...           ...             ...  \n",
      "121       11.300827      0.085139        7.657207  \n",
      "122        9.108540      0.999644        7.171907  \n",
      "123        9.148339      0.483187        7.217803  \n",
      "124        9.262157     -0.215988        6.775970  \n",
      "125        8.753542     -1.046389        6.803912  \n",
      "\n",
      "[126 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Функция для вычисления мел-кепстральных коэффициентов\n",
    "def compute_mfcc(audio, sr=22050, n_mfcc=13):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfccs\n",
    "\n",
    "# Функция для разбиения аудио на фрагменты по 20 секунд с перекрытием в 5 секунд\n",
    "def split_audio(audio, sr=22050, fragment_length=20, overlap=5):\n",
    "    fragment_samples = fragment_length * sr\n",
    "    overlap_samples = overlap * sr\n",
    "    start_samples = 0\n",
    "    fragments = []\n",
    "    while start_samples + fragment_samples <= len(audio):\n",
    "        fragments.append(audio[start_samples:start_samples+fragment_samples])\n",
    "        start_samples += overlap_samples\n",
    "    return fragments\n",
    "\n",
    "# Функция для обработки отдельного аудиофайла\n",
    "def process_audio(file_path, max_duration, fragment_length=20, overlap=5):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=None, duration=max_duration)\n",
    "        audio_length = librosa.get_duration(y=audio, sr=sr)\n",
    "        if audio_length < fragment_length:\n",
    "            return None\n",
    "        fragments = split_audio(audio, sr, fragment_length, overlap)\n",
    "        data = []\n",
    "        filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        for i, fragment in enumerate(fragments):\n",
    "            mfccs = compute_mfcc(fragment, sr)\n",
    "            mean = np.mean(mfccs, axis=1)\n",
    "            std_dev = np.std(mfccs, axis=1)\n",
    "            fragment_data = {'filename': f\"{filename}_{i+1}\"}\n",
    "            for j in range(mean.shape[0]):\n",
    "                fragment_data[f'MFCC_Mean_{j+1}'] = mean[j]\n",
    "                fragment_data[f'MFCC_StdDev_{j+1}'] = std_dev[j]\n",
    "            data.append(fragment_data)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Функция для обработки всех аудиофайлов в директории\n",
    "def process_directory(directory_path, fragment_length=20, overlap=5, max_duration=60):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.mp3'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            result = process_audio(file_path, max_duration, fragment_length, overlap)\n",
    "            if result is not None:\n",
    "                data.extend(result)\n",
    "    return data\n",
    "\n",
    "# Путь к директории с аудиофайлами\n",
    "directory_path = 'songs'\n",
    "# Обработка всех аудиофайлов в директории\n",
    "data = process_directory(directory_path)\n",
    "\n",
    "csv_path = 'songs_features.csv'\n",
    "\n",
    "try:\n",
    "    with open(csv_path, 'w') as file:\n",
    "        file.truncate(0)\n",
    "    print(f\"Файл '{csv_path}' очищен успешно.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при очистке файла '{csv_path}': {e}\")\n",
    "\n",
    "# Создание датафрейма из полученных данных\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Вывод датафрейма\n",
    "print(df)\n",
    "\n",
    "csv_path = 'songs_features.csv'\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename       labels: 126\n",
      "MFCC_Mean_1    labels: 126\n",
      "MFCC_StdDev_1  labels: 126\n",
      "MFCC_Mean_2    labels: 126\n",
      "MFCC_StdDev_2  labels: 126\n",
      "MFCC_Mean_3    labels: 126\n",
      "MFCC_StdDev_3  labels: 126\n",
      "MFCC_Mean_4    labels: 126\n",
      "MFCC_StdDev_4  labels: 126\n",
      "MFCC_Mean_5    labels: 126\n",
      "MFCC_StdDev_5  labels: 126\n",
      "MFCC_Mean_6    labels: 126\n",
      "MFCC_StdDev_6  labels: 126\n",
      "MFCC_Mean_7    labels: 126\n",
      "MFCC_StdDev_7  labels: 126\n",
      "MFCC_Mean_8    labels: 126\n",
      "MFCC_StdDev_8  labels: 126\n",
      "MFCC_Mean_9    labels: 126\n",
      "MFCC_StdDev_9  labels: 126\n",
      "MFCC_Mean_10   labels: 126\n",
      "MFCC_StdDev_10 labels: 126\n",
      "MFCC_Mean_11   labels: 126\n",
      "MFCC_StdDev_11 labels: 126\n",
      "MFCC_Mean_12   labels: 126\n",
      "MFCC_StdDev_12 labels: 126\n",
      "MFCC_Mean_13   labels: 126\n",
      "MFCC_StdDev_13 labels: 126\n"
     ]
    }
   ],
   "source": [
    "len_max = max([len(col) for col in df.columns])\n",
    "for col in df.columns:\n",
    "    print(f\"{col:<{len_max}} labels: {len(df[col].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка аудиофайлов целиком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'songs_features.csv'\n",
    "\n",
    "try:\n",
    "    with open(csv_path, 'w') as file:\n",
    "        file.truncate(0)\n",
    "    print(f\"Файл '{csv_path}' очищен успешно.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при очистке файла '{csv_path}': {e}\")\n",
    "\n",
    "\n",
    "# Путь к папке с аудиокомпозициями\n",
    "songs_dir = 'songs/'\n",
    "\n",
    "# Список имен файлов в папке songs\n",
    "file_names = os.listdir(songs_dir)\n",
    "\n",
    "# Создание пустого DataFrame с колонкой \"filename\"\n",
    "df = pd.DataFrame({'filename': file_names})\n",
    "\n",
    "# Добавление признаков в DataFrame\n",
    "for func_name, func in [('spectrum_feature', spectrum_feature),\n",
    "                        ('db_spectrum_feature', db_spectrum_feature),\n",
    "                        ('melspectrum_feature', melspectrum_feature),\n",
    "                        ('db_melspectrum_feature', db_melspectrum_feature),\n",
    "                        ('spectral_cent_feature', spectral_cent_feature),\n",
    "                        ('spectral_rolloff_feature', spectral_rolloff_feature),\n",
    "                        ('zero_crossing_feature', zero_crossing_feature)]:\n",
    "    # Применение функции к каждому файлу и добавление результатов в DataFrame\n",
    "    mean_var = df['filename'].apply(lambda x: pd.Series(func(librosa.load(songs_dir + x, sr=22050)[0]))) # решить с каналом\n",
    "    df[[f'{func_name}_mean', f'{func_name}_var']] = mean_var\n",
    "\n",
    "# Вывод DataFrame\n",
    "print(df)\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка дискретизированного аудиофайла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 8195\n",
    "sr = 22050\n",
    "hop_length = n_fft // 2\n",
    "segment_duration = 20  # Длительность каждого сегмента в секундах\n",
    "segment_samples = segment_duration * sr  # Количество отсчетов в каждом сегменте\n",
    "\n",
    "def segment_audio(signal, sr, segment_duration):\n",
    "    # Разбиваем аудиозапись на сегменты по segment_duration секунд\n",
    "    segments = []\n",
    "    for start_sample in range(0, len(signal), segment_duration * sr):\n",
    "        segment = signal[start_sample:start_sample + segment_duration * sr]\n",
    "        # Если сегмент короче ожидаемой длительности, дополним его нулями\n",
    "        if len(segment) < segment_duration * sr:\n",
    "            segment = np.concatenate([segment, np.zeros(segment_duration * sr - len(segment))])\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "def extract_features(signal):\n",
    "    features = {}\n",
    "    features['spectrum_mean'], features['spectrum_var'] = spectrum_feature(signal)\n",
    "    features['db_spectrum_mean'], features['db_spectrum_var'] = db_spectrum_feature(signal)\n",
    "    features['melspectrum_mean'], features['melspectrum_var'] = melspectrum_feature(signal)\n",
    "    features['db_melspectrum_mean'], features['db_melspectrum_var'] = db_melspectrum_feature(signal)\n",
    "    features['spectral_cent_mean'], features['spectral_cent_var'] = spectral_cent_feature(signal)\n",
    "    features['spectral_rolloff_mean'], features['spectral_rolloff_var'] = spectral_rolloff_feature(signal)\n",
    "    features['zero_crossing_mean'], features['zero_crossing_var'] = zero_crossing_feature(signal)\n",
    "    return features\n",
    "\n",
    "\n",
    "csv_path = 'songs_features.csv'\n",
    "\n",
    "try:\n",
    "    with open(csv_path, 'w') as file:\n",
    "        file.truncate(0)\n",
    "    print(f\"Файл '{csv_path}' очищен успешно.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при очистке файла '{csv_path}': {e}\")\n",
    "\n",
    "# Путь к папке с аудиокомпозициями\n",
    "songs_dir = 'songs/'\n",
    "\n",
    "# Список имен файлов в папке songs\n",
    "file_names = os.listdir(songs_dir)\n",
    "\n",
    "# Создание пустого списка для хранения словарей признаков\n",
    "segments_data = []\n",
    "\n",
    "# Добавление признаков в DataFrame для каждого сегмента каждой композиции\n",
    "\n",
    "for filename in file_names:\n",
    "    file_path = os.path.join(songs_dir, filename)\n",
    "    signal, sr = librosa.load(file_path, sr=sr)\n",
    "    segments = segment_audio(signal, sr, segment_duration)\n",
    "    for i, segment in enumerate(segments):\n",
    "        # Обрезаем тишину в начале и в конце сегмента\n",
    "        segment, _ = librosa.effects.trim(segment) # эта строка убирается, если тишину необходимо оставить\n",
    "        features = extract_features(segment)\n",
    "        segment_data = {'filename': f\"{filename[:-4]}_{i+1}\", **features}\n",
    "        segments_data.append(segment_data)\n",
    "\n",
    "# Создание DataFrame из списка словарей\n",
    "df = pd.DataFrame(segments_data)\n",
    "\n",
    "# Вывод DataFrame\n",
    "print(df)\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy.stats import moment\n",
    "\n",
    "n_fft = 8195\n",
    "sr = 22050\n",
    "hop_length = n_fft // 2\n",
    "segment_duration = 20  # Длительность каждого сегмента в секундах\n",
    "segment_samples = segment_duration * sr  # Количество отсчетов в каждом сегменте\n",
    "\n",
    "def segment_audio(signal, sr, segment_duration, overlap):\n",
    "    # Разбиваем аудиозапись на сегменты по segment_duration секунд с перекрытием overlap\n",
    "    segments = []\n",
    "    start = 0\n",
    "    while start + segment_duration <= len(signal) / sr:\n",
    "        segment = signal[int(start * sr): int((start + segment_duration) * sr)]\n",
    "        # Если сегмент короче ожидаемой длительности, дополним его нулями\n",
    "        if len(segment) < segment_duration * sr:\n",
    "            segment = np.concatenate([segment, np.zeros(segment_duration * sr - len(segment))])\n",
    "        segments.append(segment)\n",
    "        start += overlap\n",
    "    return segments\n",
    "\n",
    "def extract_features(signal):\n",
    "    features = {}\n",
    "    features['spectrum_mean'], features['spectrum_var'] = spectrum_feature(signal)\n",
    "    features['db_spectrum_mean'], features['db_spectrum_var'] = db_spectrum_feature(signal)\n",
    "    features['melspectrum_mean'], features['melspectrum_var'] = melspectrum_feature(signal)\n",
    "    features['db_melspectrum_mean'], features['db_melspectrum_var'] = db_melspectrum_feature(signal)\n",
    "    features['spectral_cent_mean'], features['spectral_cent_var'] = spectral_cent_feature(signal)\n",
    "    features['spectral_rolloff_mean'], features['spectral_rolloff_var'] = spectral_rolloff_feature(signal)\n",
    "    features['zero_crossing_mean'], features['zero_crossing_var'] = zero_crossing_feature(signal)\n",
    "    return features\n",
    "\n",
    "\n",
    "csv_path = 'songs_features.csv'\n",
    "\n",
    "try:\n",
    "    with open(csv_path, 'w') as file:\n",
    "        file.truncate(0)\n",
    "    print(f\"Файл '{csv_path}' очищен успешно.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при очистке файла '{csv_path}': {e}\")\n",
    "\n",
    "# Путь к папке с аудиокомпозициями\n",
    "songs_dir = 'songs/'\n",
    "\n",
    "# Список имен файлов в папке songs\n",
    "file_names = os.listdir(songs_dir)\n",
    "\n",
    "# Создание пустого списка для хранения словарей признаков\n",
    "segments_data = []\n",
    "\n",
    "# Добавление признаков в DataFrame для каждого сегмента каждой композиции\n",
    "\n",
    "for filename in file_names:\n",
    "    file_path = os.path.join(songs_dir, filename)\n",
    "    signal, sr = librosa.load(file_path, sr=sr)\n",
    "    segments = segment_audio(signal, sr, segment_duration, segment_duration - 5)  # Изменение с перекрытием\n",
    "    for i, segment in enumerate(segments):\n",
    "        # Обрезаем тишину в начале и в конце сегмента\n",
    "        segment, _ = librosa.effects.trim(segment) # эта строка убирается, если тишину необходимо оставить\n",
    "        features = extract_features(segment)\n",
    "        segment_data = {'filename': f\"{filename[:-4]}_{i+1}\", **features}\n",
    "        segments_data.append(segment_data)\n",
    "\n",
    "# Создание DataFrame из списка словарей\n",
    "df = pd.DataFrame(segments_data)\n",
    "\n",
    "# Вывод DataFrame\n",
    "print(df)\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('songs_features.csv')\n",
    "filename_new = 'test_data/Timbaland_-_Apologize_47972715.mp3'\n",
    "signal = librosa.load(filename_new, sr=22050)[0] #, duration=20\n",
    "spectrum_mean, spectrum_var = spectrum_feature(signal)\n",
    "db_spectrum_mean, db_spectrum_var = db_spectrum_feature(signal)\n",
    "melspectrum_mean, melspectrum_var = melspectrum_feature(signal)\n",
    "db_melspectrum_mean, db_melspectrum_var = db_melspectrum_feature(signal)\n",
    "spectral_cent_mean, spectral_cent_var = spectral_cent_feature(signal)\n",
    "spectral_rolloff_mean, spectral_rolloff_var = spectral_rolloff_feature(signal)\n",
    "zero_crossing_mean, zero_crossing_var = zero_crossing_feature(signal)\n",
    "\n",
    "new_features = [spectrum_mean, spectrum_var, db_spectrum_mean, db_spectrum_var, melspectrum_mean, melspectrum_var, db_melspectrum_mean, db_melspectrum_var, spectral_cent_mean, spectral_cent_var, spectral_rolloff_mean, spectral_rolloff_var, zero_crossing_mean, zero_crossing_var]\n",
    "new_features = np.array(new_features).reshape(1, -1)\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop(columns=['filename'])\n",
    "print(X)\n",
    "print('Features:')\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск по дистанциям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислите расстояния между наборами признаков\n",
    "distances = np.linalg.norm(X.values - new_features, axis=1)\n",
    "\n",
    "# Найдите индексы строк с минимальными расстояниями (включая самый близкий)\n",
    "closest_indices = np.argsort(distances)[:11]  # Выбираем первые четыре индекса с наименьшими расстояниями\n",
    "\n",
    "# Получите названия файлов из найденных строк\n",
    "closest_files = df.iloc[closest_indices]['filename']\n",
    "\n",
    "# Получите признаки из найденных строк\n",
    "closest_features = X.iloc[closest_indices].values\n",
    "\n",
    "print(\"Признаки новой композиции:\")\n",
    "print(new_features)\n",
    "\n",
    "print(\"\\nДругие похожие файлы и их признаки:\")\n",
    "for i in range(len(closest_indices)):\n",
    "    print(f\"\\nФайл {i+1}: {closest_files.iloc[i]}\")\n",
    "    print(closest_features[i])\n",
    "    print(\"Расстояние:\", distances[closest_indices[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск по сумме дистанций фрагментов (только для дискретизованных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте словарь для хранения сумм расстояний по композициям\n",
    "sum_distances = {}\n",
    "\n",
    "# Проход по каждой строке DataFrame X (признаки каждого фрагмента)\n",
    "for index, row in df.iterrows():\n",
    "    # Преобразуйте индекс в строку и получите название композиции из индекса строки\n",
    "    composition_name = row['filename'].split('_')[0]\n",
    "    \n",
    "    # Если композиция еще не добавлена в словарь, добавьте ее\n",
    "    if composition_name not in sum_distances:\n",
    "        sum_distances[composition_name] = 0\n",
    "    \n",
    "    # Вычислите расстояние между текущим фрагментом и новой композицией\n",
    "    distance = np.linalg.norm(X.values - new_features)\n",
    "    \n",
    "    # Добавьте расстояние к сумме расстояний для данной композиции\n",
    "    sum_distances[composition_name] += distance\n",
    "\n",
    "# Преобразуйте словарь в DataFrame для удобства обработки\n",
    "sum_distances_df = pd.DataFrame(list(sum_distances.items()), columns=['Composition', 'Sum Distance'])\n",
    "\n",
    "# Найдите наиболее похожие композиции на основе сумм расстояний\n",
    "closest_compositions = sum_distances_df.nsmallest(11, 'Sum Distance')\n",
    "\n",
    "# Выведите результаты\n",
    "print(\"Наиболее похожие композиции:\")\n",
    "for index, row in closest_compositions.iterrows():\n",
    "    print(f\"{row['Composition']}, Сумма расстояний: {row['Sum Distance']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск для MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('songs_features.csv')\n",
    "filename_new = 'test_data/Timbaland_feat_OneRepublic_-_Apologize_NORTKASH_Zusebi_Remix_73927193.mp3'\n",
    "result = process_audio(filename_new, 20, fragment_length=20, overlap=5)\n",
    "result = list(result[0].values())[1:]\n",
    "new_features = np.array(result).reshape(1, -1)\n",
    "\n",
    "X = df.drop(columns=['filename'])\n",
    "print('Features:')\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислите расстояния между наборами признаков\n",
    "distances = np.linalg.norm(X.values - new_features, axis=1)\n",
    "\n",
    "# Найдите индексы строк с минимальными расстояниями (включая самый близкий)\n",
    "closest_indices = np.argsort(distances)[:11]  # Выбираем первые четыре индекса с наименьшими расстояниями\n",
    "\n",
    "# Получите названия файлов из найденных строк\n",
    "closest_files = df.iloc[closest_indices]['filename']\n",
    "\n",
    "# Получите признаки из найденных строк\n",
    "closest_features = X.iloc[closest_indices].values\n",
    "\n",
    "print(\"Признаки новой композиции:\")\n",
    "print(new_features)\n",
    "\n",
    "print(\"\\nДругие похожие файлы и их признаки:\")\n",
    "for i in range(len(closest_indices)):\n",
    "    print(f\"\\nФайл {i+1}: {closest_files.iloc[i]}\")\n",
    "    print(closest_features[i])\n",
    "    print(\"Расстояние:\", distances[closest_indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('songs_features.csv')\n",
    "filename_new = 'test_data/7 Seconds from middle small.mp3'\n",
    "result = process_audio(filename_new, 20, fragment_length=20, overlap=5)\n",
    "result = list(result[0].values())[1:]\n",
    "new_features = np.array(result).reshape(1, -1)\n",
    "\n",
    "# Исключаем столбец с именем файла\n",
    "X = df.drop(columns=['filename'])\n",
    "\n",
    "# Создание модели kNN\n",
    "k = 11  # количество соседей\n",
    "knn = NearestNeighbors(n_neighbors=k)\n",
    "knn.fit(X)\n",
    "\n",
    "# Поиск ближайших соседей\n",
    "distances, indices = knn.kneighbors(new_features)\n",
    "\n",
    "# Получение информации о ближайших соседях\n",
    "closest_files = df.iloc[indices[0]]['filename']\n",
    "closest_features = X.iloc[indices[0]].values\n",
    "\n",
    "print(\"Признаки новой композиции:\")\n",
    "print(new_features)\n",
    "\n",
    "print(\"\\nДругие похожие файлы и их признаки:\")\n",
    "for i in range(len(closest_files)):\n",
    "    print(f\"\\nФайл {i+1}: {closest_files.iloc[i]}\")\n",
    "    print(closest_features[i])\n",
    "    print(\"Расстояние:\", distances[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('songs_features.csv')\n",
    "filename_new = 'test_data/7 Seconds from middle small.mp3'\n",
    "result = process_audio(filename_new, 20, fragment_length=20, overlap=5)\n",
    "result = list(result[0].values())[1:]\n",
    "new_features = np.array(result).reshape(1, -1)\n",
    "\n",
    "X = df.drop(columns=['filename'])\n",
    "\n",
    "# Вычислите косинусное сходство между наборами признаков\n",
    "similarities = cosine_similarity(X, new_features)\n",
    "\n",
    "# Найдите индексы строк с максимальным косинусным сходством (включая самый близкий)\n",
    "closest_indices = np.argsort(similarities, axis=0)[-11:].flatten()\n",
    "\n",
    "# Получите названия файлов из найденных строк\n",
    "closest_files = df.iloc[closest_indices]['filename']\n",
    "\n",
    "# Получите признаки из найденных строк\n",
    "closest_features = X.iloc[closest_indices].values\n",
    "\n",
    "print(\"Признаки новой композиции:\")\n",
    "print(new_features)\n",
    "\n",
    "print(\"\\nДругие похожие файлы и их признаки:\")\n",
    "for i in range(len(closest_indices)):\n",
    "    print(f\"\\nФайл {i+1}: {closest_files.iloc[i]}\")\n",
    "    print(closest_features[i])\n",
    "    print(\"Косинусное сходство:\", similarities[closest_indices[i]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте словарь для хранения сумм расстояний по композициям\n",
    "sum_distances = {}\n",
    "\n",
    "# Проход по каждой строке DataFrame X (признаки каждого фрагмента)\n",
    "for index, row in df.iterrows():\n",
    "    # Преобразуйте индекс в строку и получите название композиции из индекса строки\n",
    "    composition_name = row['filename'].split('_')[0]\n",
    "    \n",
    "    # Если композиция еще не добавлена в словарь, добавьте ее\n",
    "    if composition_name not in sum_distances:\n",
    "        sum_distances[composition_name] = 0\n",
    "    \n",
    "    # Вычислите евклидово расстояние между текущим фрагментом и новой композицией\n",
    "    distance = np.linalg.norm(row.values[1:] - new_features)\n",
    "    \n",
    "    # Добавьте расстояние к сумме расстояний для данной композиции\n",
    "    sum_distances[composition_name] += distance\n",
    "\n",
    "# Преобразуйте словарь в DataFrame для удобства обработки\n",
    "sum_distances_df = pd.DataFrame(list(sum_distances.items()), columns=['Composition', 'Sum Distance'])\n",
    "\n",
    "closest_compositions = sum_distances_df.nsmallest(11, 'Sum Distance')\n",
    "\n",
    "print(\"Наиболее похожие композиции:\")\n",
    "for index, row in closest_compositions.iterrows():\n",
    "    print(f\"{row['Composition']}, Сумма расстояний: {row['Sum Distance']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка всех файлов директории, создание датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 8195\n",
    "sr = 22050\n",
    "hop_length = n_fft // 2\n",
    "\n",
    "def spectrum_feature(signal):\n",
    "    ft = np.abs(librosa.stft(signal[:n_fft], n_fft=n_fft, hop_length=hop_length))\n",
    "    mean_ft = np.mean(ft, axis=1)  # Усредняем по всем каналам\n",
    "\n",
    "    return np.mean(mean_ft), np.var(mean_ft)\n",
    "\n",
    "def db_spectrum_feature(signal):\n",
    "    X = librosa.stft(signal)\n",
    "    s = librosa.amplitude_to_db(abs(X))\n",
    "\n",
    "    return np.mean(s), np.var(s)\n",
    "\n",
    "def melspectrum_feature(signal):\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc = 40, hop_length=512)\n",
    "\n",
    "    return np.mean(mfccs), np.var(mfccs)\n",
    "\n",
    "def db_melspectrum_feature(signal):\n",
    "    melspectrum = librosa.feature.melspectrogram(y=signal, sr=sr, hop_length=512, n_mels=40)\n",
    "    melspectrum_db = librosa.power_to_db(melspectrum, ref=np.max)  # Преобразуем в децибелы\n",
    "\n",
    "    return np.mean(melspectrum_db), np.var(melspectrum_db)\n",
    "\n",
    "def spectral_cent_feature(signal):\n",
    "    cent = librosa.feature.spectral_centroid(y=signal, sr=sr)\n",
    "\n",
    "    return np.mean(cent), np.var(cent)\n",
    "\n",
    "def spectral_rolloff_feature(signal):\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=signal, sr=sr)\n",
    "\n",
    "    return np.mean(rolloff), np.var(rolloff)\n",
    "\n",
    "def zero_crossing_feature(signal):\n",
    "    zrate=librosa.feature.zero_crossing_rate(signal)\n",
    "\n",
    "    return np.mean(zrate), np.var(zrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка аудиофайлов целиком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл 'songs_features.csv' очищен успешно.\n",
      "                                             filename  MFCC_Mean_1  \\\n",
      "0         7 Seconds -- Youssou N'Dour, Neneh Cherry_1  -551.628662   \n",
      "1         7 Seconds -- Youssou N'Dour, Neneh Cherry_2  -140.451599   \n",
      "2         7 Seconds -- Youssou N'Dour, Neneh Cherry_3  -170.317963   \n",
      "3                                a-ha -- Take On Me_1  -540.525757   \n",
      "4                                a-ha -- Take On Me_2  -126.084801   \n",
      "5                                a-ha -- Take On Me_3   -64.118607   \n",
      "6                       ABBA -- Money, Money, Money_1  -543.826843   \n",
      "7                       ABBA -- Money, Money, Money_2  -212.842972   \n",
      "8                       ABBA -- Money, Money, Money_3  -137.955460   \n",
      "9                   ABBA -- The Winner Takes It All_1  -698.643555   \n",
      "10                  ABBA -- The Winner Takes It All_2  -212.278900   \n",
      "11                  ABBA -- The Winner Takes It All_3  -301.265747   \n",
      "12                          All The Things She Said_1  -510.713715   \n",
      "13                          All The Things She Said_2   -40.982365   \n",
      "14                          All The Things She Said_3  -162.158661   \n",
      "15                          Animals — Martin Garrix_1  -431.970276   \n",
      "16                          Animals — Martin Garrix_2  -216.796173   \n",
      "17                          Animals — Martin Garrix_3  -141.475113   \n",
      "18               Another One Bites The Dust — Queen_1  -406.255463   \n",
      "19               Another One Bites The Dust — Queen_2  -165.557709   \n",
      "20               Another One Bites The Dust — Queen_3  -229.421112   \n",
      "21                                        Apologize_1  -589.074219   \n",
      "22                                        Apologize_2  -208.637299   \n",
      "23                                        Apologize_3  -120.283447   \n",
      "24                                        Appletree_1  -386.021210   \n",
      "25                                        Appletree_2  -331.182159   \n",
      "26                                        Appletree_3  -181.883270   \n",
      "27  B.o.B, Hayley Williams of Paramore -- Airplane...  -611.328430   \n",
      "28  B.o.B, Hayley Williams of Paramore -- Airplane...  -168.779007   \n",
      "29  B.o.B, Hayley Williams of Paramore -- Airplane...   -79.563904   \n",
      "30                     B.o.B, Jessie J -- Price Tag_1  -509.798096   \n",
      "31                     B.o.B, Jessie J -- Price Tag_2  -139.020538   \n",
      "32                     B.o.B, Jessie J -- Price Tag_3   -92.250366   \n",
      "33                                     Bad Bad Boys_1  -548.252319   \n",
      "34                                     Bad Bad Boys_2  -147.593521   \n",
      "35                                     Bad Bad Boys_3  -169.818787   \n",
      "36                                      Bad Romance_1  -525.605286   \n",
      "37                                      Bad Romance_2  -164.104034   \n",
      "38                                      Bad Romance_3   -80.023911   \n",
      "39                    Bag Raiders -- Shooting stars_1  -528.510498   \n",
      "40                    Bag Raiders -- Shooting stars_2  -205.724564   \n",
      "41                    Bag Raiders -- Shooting stars_3   -75.113876   \n",
      "\n",
      "    MFCC_StdDev_1  MFCC_Mean_2  MFCC_StdDev_2  MFCC_Mean_3  MFCC_StdDev_3  \\\n",
      "0        0.079644     0.037284       0.112580     0.037224       0.112397   \n",
      "1       73.909035   133.146637      36.859985   -12.729688      16.606283   \n",
      "2       17.345057   144.181107       7.941437    -3.464936      11.982671   \n",
      "3        0.000122     0.000000       0.000000     0.000000       0.000000   \n",
      "4       27.132071   105.164627       9.756879   -50.529011       6.082672   \n",
      "5       16.832825    87.003433      31.712851   -27.930466       9.028651   \n",
      "6        0.000061     0.000000       0.000000     0.000000       0.000000   \n",
      "7       47.134281    99.508018      59.184860   -12.221830      17.481850   \n",
      "8       12.088894   166.651688       4.734403   -53.766792       8.635323   \n",
      "9        0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "10      10.006631   181.620514      11.315223   -64.777420      14.970247   \n",
      "11       9.408735   153.044861       6.692393   -27.096701       3.742423   \n",
      "12       6.091226     3.140622       8.347273     2.851246       7.569513   \n",
      "13      17.487568   142.391449      15.707569   -50.151428      10.978601   \n",
      "14      49.879593   115.952835      34.020813   -16.794544      25.323502   \n",
      "15     232.814224    35.134789      51.776150    -0.509485      30.983591   \n",
      "16      21.672012   105.671951      20.217266     0.972992      15.058955   \n",
      "17      56.652260   104.288109      22.451235    25.467930      24.652632   \n",
      "18      66.499100   124.084328      81.887062    85.452545      55.329315   \n",
      "19      65.240242   179.106598      53.636963    10.725156      14.181095   \n",
      "20     111.688217   135.004745      13.388522   -40.217442       7.322448   \n",
      "21       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "22      54.215588   149.165527      50.754787     7.921102       6.448903   \n",
      "23      21.653496   146.251617       8.604323   -35.804176      15.381997   \n",
      "24     145.294952    53.643658      66.039757    11.825502      14.456481   \n",
      "25      41.811943   113.390244      36.378517    38.866051       7.471129   \n",
      "26      81.776100   141.371246      10.895990   -17.869785      32.568474   \n",
      "27       0.000061     0.000000       0.000000     0.000000       0.000000   \n",
      "28      31.149975   166.861069      21.662010   -23.501974      10.791239   \n",
      "29      31.556187   144.266663      10.462183   -73.892136      12.341786   \n",
      "30       0.000031     0.000000       0.000000     0.000000       0.000000   \n",
      "31      17.831446   103.494530      38.996838    10.851679      21.552973   \n",
      "32      25.837334    83.925003      24.901159   -12.167480      33.595142   \n",
      "33       0.000061     0.000000       0.000000     0.000000       0.000000   \n",
      "34      35.103951   124.199318      18.087898   -30.874411      15.297522   \n",
      "35      59.606293   105.148827      26.433662    -2.062860      25.792704   \n",
      "36       0.000061     0.000000       0.000000     0.000000       0.000000   \n",
      "37      29.969702   106.844131      10.448571   -86.372993      10.387948   \n",
      "38      37.330921   104.140419      25.322823   -23.916534      11.758021   \n",
      "39       0.000061     0.000000       0.000000     0.000000       0.000000   \n",
      "40      24.086445   125.439941      21.763302    -7.384875       7.324900   \n",
      "41      56.975735   145.720810      22.803484   -26.228825      15.736166   \n",
      "\n",
      "    MFCC_Mean_4  MFCC_StdDev_4  MFCC_Mean_5  ...  MFCC_Mean_1709  \\\n",
      "0      0.037124       0.112092     0.036983  ...       -2.526753   \n",
      "1     60.990944      14.656424    -1.937224  ...       -5.109684   \n",
      "2     59.684132       8.874779     7.068476  ...       -6.994823   \n",
      "3      0.000000       0.000000     0.000000  ...      -18.416729   \n",
      "4     48.204617       9.038143   -22.749680  ...      -19.812977   \n",
      "5     70.457397      16.919859   -34.901440  ...       -3.852580   \n",
      "6      0.000000       0.000000     0.000000  ...       18.652401   \n",
      "7     57.848877      17.253298   -22.976421  ...        0.981779   \n",
      "8     34.158005       5.597289   -20.786764  ...       -0.020060   \n",
      "9      0.000000       0.000000     0.000000  ...       -4.233730   \n",
      "10    24.253485       8.671930     0.541681  ...       -1.807873   \n",
      "11    30.145618       5.328917    -9.443592  ...       -7.423786   \n",
      "12     2.395944       6.348495     1.812279  ...      -10.009078   \n",
      "13    51.508492       9.701327    -7.987129  ...      -13.406512   \n",
      "14    54.071552      23.647057   -17.653864  ...      -14.882212   \n",
      "15    24.798389      33.027370   -11.643114  ...      -20.324022   \n",
      "16     6.529768      11.912170   -43.759029  ...       -1.416720   \n",
      "17    54.907146      12.070357    -4.943400  ...      -19.931223   \n",
      "18    45.413551      32.177536    19.327293  ...        1.914996   \n",
      "19    17.573372      32.189224     2.466988  ...        1.160762   \n",
      "20    33.942802      15.562123    42.354721  ...      -10.726445   \n",
      "21     0.000000       0.000000     0.000000  ...       -7.337672   \n",
      "22    40.734226      17.896917    -0.473534  ...       -4.745599   \n",
      "23    44.909824       7.507397     7.232652  ...      -14.731903   \n",
      "24    30.605900      37.294773     1.357275  ...       -1.191130   \n",
      "25    40.516830      23.359863     8.945206  ...        8.347946   \n",
      "26    73.716476       9.533351    31.013458  ...       15.187920   \n",
      "27     0.000000       0.000000     0.000000  ...      -23.630383   \n",
      "28    18.768147       8.720386    27.857716  ...       -9.774899   \n",
      "29    51.129913       3.938030    -8.246510  ...       -1.544824   \n",
      "30     0.000000       0.000000     0.000000  ...       -3.469547   \n",
      "31    64.572655      15.431936   -16.342335  ...      -13.457697   \n",
      "32    62.310493      13.990856    -3.064086  ...       -3.911130   \n",
      "33     0.000000       0.000000     0.000000  ...      -20.875441   \n",
      "34    76.508499       8.514771    17.508383  ...       -7.048441   \n",
      "35    74.112915      11.320477    -6.627864  ...      -12.940475   \n",
      "36     0.000000       0.000000     0.000000  ...      -11.040556   \n",
      "37    -6.234852      12.275872   -55.216827  ...       15.058004   \n",
      "38    69.086739      12.007387   -23.625040  ...       -3.558772   \n",
      "39     0.000000       0.000000     0.000000  ...      -16.760471   \n",
      "40    30.879730      15.076756   -23.206861  ...       -3.109018   \n",
      "41    33.944592       6.754634   -11.722040  ...       -1.917937   \n",
      "\n",
      "    MFCC_StdDev_1709  MFCC_Mean_1710  MFCC_StdDev_1710  MFCC_Mean_1711  \\\n",
      "0           6.131948        4.780341          8.683071        7.369267   \n",
      "1           9.640541        7.154967         10.196951      -19.504120   \n",
      "2           4.996693       10.499163          9.180041        2.644416   \n",
      "3           7.279272       16.304823         10.770811      -10.500420   \n",
      "4           9.577719        6.418507          6.337804      -19.896580   \n",
      "5           6.266428       10.109010          8.182673      -13.953214   \n",
      "6           9.795918        9.466798          6.104993        8.547623   \n",
      "7           8.212350       -6.406222          8.935480       -1.236353   \n",
      "8           7.397289       -6.107119         11.377862       -8.946280   \n",
      "9           3.052024        1.491578          4.497806       -9.144144   \n",
      "10          3.390373        3.964611          3.740147       -4.557900   \n",
      "11          3.381504        0.279088          6.639924       -1.204161   \n",
      "12          5.596741       13.132210          7.237491        1.028089   \n",
      "13         12.722734       19.523390          6.437076        8.473376   \n",
      "14          5.684218       10.411564          6.538893       -3.530102   \n",
      "15          5.342761       24.521137          8.591320        1.761292   \n",
      "16          5.799727       15.312857          3.322820       13.265465   \n",
      "17          3.896464       30.506954          2.960005       -3.112844   \n",
      "18         11.388505       18.215099          8.854322        3.382257   \n",
      "19          8.340545       14.950002          6.536916        7.665657   \n",
      "20         11.313426       15.982483         12.175591       -9.170973   \n",
      "21          6.625738       23.108738          4.898608        5.451129   \n",
      "22          2.836260       29.703724          1.877604        5.723918   \n",
      "23          6.018153       23.577808          3.957766       -0.404443   \n",
      "24          3.207497        3.315886          6.584237       -3.630312   \n",
      "25          4.777725        3.548070          4.953171       -0.621242   \n",
      "26          3.810590      -11.847737          9.255542        9.597818   \n",
      "27          6.045787       14.567378          5.105982       -4.083207   \n",
      "28          9.114068        3.439068          6.581534       -2.240011   \n",
      "29         12.443049       10.690782          8.371462       -5.976135   \n",
      "30          9.143907       14.487699          9.413201       -0.672009   \n",
      "31          4.777563        1.282591         12.419371      -14.457105   \n",
      "32          5.603885       13.718030          3.717249        3.661793   \n",
      "33         10.344994        5.399659          7.189334        7.914798   \n",
      "34          5.225502       24.095718          7.969576        3.563339   \n",
      "35          4.219190       19.004944          4.543136       11.464418   \n",
      "36          8.580479       -5.675467          7.708080      -18.688643   \n",
      "37         12.819744        4.062249          6.422496       10.895606   \n",
      "38          7.883296       11.764097          6.226805        9.644739   \n",
      "39          7.195995        9.978156         16.324406      -23.396749   \n",
      "40          7.854151        0.410788          9.543352       -8.937990   \n",
      "41          6.446477        8.770496          5.873132       -7.133779   \n",
      "\n",
      "    MFCC_StdDev_1711  MFCC_Mean_1712  MFCC_StdDev_1712  MFCC_Mean_1713  \\\n",
      "0           6.705924        8.678045          7.033219       10.294884   \n",
      "1           8.354777        6.628638          8.801067       -3.684107   \n",
      "2           9.851319        8.606803          7.268103        3.354514   \n",
      "3           7.248290        9.501490          6.074573       -1.276708   \n",
      "4           7.948774        2.131605          8.085495       -6.469855   \n",
      "5           5.089666       19.850885          8.447357       -1.043190   \n",
      "6          10.110573        7.048319          4.085832        2.584275   \n",
      "7           4.249363      -12.100863          6.464947      -11.691568   \n",
      "8           9.072488       -7.551921          8.043775       -3.811932   \n",
      "9           4.113769        0.498065          2.952008       -9.666319   \n",
      "10          3.343988      -15.827487          3.901482       -8.047405   \n",
      "11          4.375847        0.070783          2.918132      -13.627292   \n",
      "12          7.682788        4.050352          5.578774      -10.777191   \n",
      "13          6.698241       -2.175899          4.158447       -6.385069   \n",
      "14          6.433259        4.759531          5.050611       -9.151086   \n",
      "15         11.726727       21.187777         11.334102       -0.909000   \n",
      "16          3.994992       13.785509          4.148507        9.527196   \n",
      "17          4.923899       19.606394          3.633007        7.424399   \n",
      "18          7.077783       -1.122748          4.712785       -5.661450   \n",
      "19          7.072999        1.886367          9.657289       -0.776698   \n",
      "20          7.701508        5.497976          8.650657       -2.622101   \n",
      "21          7.022425       13.925524          8.141850        5.881331   \n",
      "22          3.101544       22.991535          3.433464        9.793132   \n",
      "23          4.401062       24.045177          4.769039        2.788186   \n",
      "24          3.857655        1.951856          4.236540        5.767238   \n",
      "25          3.553822        1.090325          3.680540        0.523356   \n",
      "26          5.220690        8.058523          1.390507       -0.886199   \n",
      "27          6.171620        2.526099          6.908802       -2.737649   \n",
      "28          7.734203       -6.794749          4.245098        2.676401   \n",
      "29         15.348561      -10.336071          3.372792        5.818459   \n",
      "30          4.524796       -3.332744          8.803414      -11.531053   \n",
      "31          7.426422       -8.833011          9.466564      -10.752690   \n",
      "32          5.887709       12.125895          6.299882       -4.809464   \n",
      "33          5.751424        2.427805          7.828094        7.390124   \n",
      "34          4.902435        8.619333          5.700520        8.045592   \n",
      "35          8.256777        1.922205          6.221062        0.566355   \n",
      "36          5.235519      -12.467699          7.452407      -10.598659   \n",
      "37          5.892281       15.165880          6.042431        9.313425   \n",
      "38          6.030788       15.202304          6.274531       -1.708229   \n",
      "39          8.908998      -11.617017          7.970385       -1.166970   \n",
      "40          8.301240       -0.649662         10.322021        2.127638   \n",
      "41          6.835815        3.160581          7.215387       -6.345877   \n",
      "\n",
      "    MFCC_StdDev_1713  \n",
      "0           4.785868  \n",
      "1           4.906019  \n",
      "2           6.774383  \n",
      "3           7.521977  \n",
      "4           5.893600  \n",
      "5           5.542519  \n",
      "6           4.623322  \n",
      "7           5.909820  \n",
      "8           6.816233  \n",
      "9           2.317335  \n",
      "10          3.506973  \n",
      "11          4.396838  \n",
      "12          2.898543  \n",
      "13          4.526077  \n",
      "14          5.230951  \n",
      "15          4.420795  \n",
      "16          3.982554  \n",
      "17          2.905208  \n",
      "18          2.892503  \n",
      "19          3.120563  \n",
      "20          6.049907  \n",
      "21          6.089235  \n",
      "22          5.071769  \n",
      "23          3.832723  \n",
      "24          3.949103  \n",
      "25          3.281232  \n",
      "26          3.487197  \n",
      "27          3.056773  \n",
      "28          5.429125  \n",
      "29          6.164062  \n",
      "30          7.698053  \n",
      "31          3.734691  \n",
      "32          4.763243  \n",
      "33          2.744985  \n",
      "34          6.353351  \n",
      "35          4.351679  \n",
      "36          6.691589  \n",
      "37          5.549770  \n",
      "38          6.905144  \n",
      "39          8.594438  \n",
      "40          4.426038  \n",
      "41          4.143478  \n",
      "\n",
      "[42 rows x 2237 columns]\n"
     ]
    }
   ],
   "source": [
    "# Функция для вычисления мел-кепстральных коэффициентов\n",
    "def compute_mfcc(audio, sr=22050, n_mfcc=13):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfccs\n",
    "\n",
    "# Функция для разбиения аудио на фрагменты по 20 секунд\n",
    "def split_audio(audio, sr=22050, fragment_length=20):\n",
    "    fragment_samples = fragment_length * sr\n",
    "    num_fragments = len(audio) // fragment_samples\n",
    "    fragments = [audio[i*fragment_samples:(i+1)*fragment_samples] for i in range(num_fragments)]\n",
    "    return fragments\n",
    "\n",
    "# Функция для разбиения мел-кепстральных коэффициентов на группы по 20 элементов\n",
    "def split_mfcc(mfccs, group_size=20):\n",
    "    num_frames = mfccs.shape[1]\n",
    "    num_groups = num_frames // group_size\n",
    "    mfcc_groups = [mfccs[:, i*group_size:(i+1)*group_size] for i in range(num_groups)]\n",
    "    return mfcc_groups\n",
    "\n",
    "# Функция для обработки отдельного аудиофайла\n",
    "def process_audio(file_path, max_duration, fragment_length=20, group_size=20):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=None, duration=max_duration)\n",
    "        audio_length = librosa.get_duration(y=audio, sr=sr)\n",
    "        if audio_length < fragment_length:\n",
    "            return None\n",
    "        fragments = split_audio(audio, sr, fragment_length)\n",
    "        data = []\n",
    "        filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        for i, fragment in enumerate(fragments):\n",
    "            mfccs = compute_mfcc(fragment, sr)\n",
    "            mfcc_groups = split_mfcc(mfccs, group_size)\n",
    "            fragment_data = {'filename': f\"{filename}_{i+1}\"}\n",
    "            for j, group in enumerate(mfcc_groups):\n",
    "                mean = np.mean(group, axis=1)\n",
    "                std_dev = np.std(group, axis=1)\n",
    "                for k in range(mean.shape[0]):\n",
    "                    fragment_data[f'MFCC_Mean_{(j*group_size)+k+1}'] = mean[k]\n",
    "                    fragment_data[f'MFCC_StdDev_{(j*group_size)+k+1}'] = std_dev[k]\n",
    "            data.append(fragment_data)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Функция для обработки всех аудиофайлов в директории\n",
    "def process_directory(directory_path, fragment_length=20, group_size=20, max_duration=60):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.mp3'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            result = process_audio(file_path, max_duration, fragment_length, group_size)\n",
    "            if result is not None:\n",
    "                data.extend(result)\n",
    "    return data\n",
    "\n",
    "# Путь к директории с аудиофайлами\n",
    "directory_path = 'songs'\n",
    "# Обработка всех аудиофайлов в директории\n",
    "data = process_directory(directory_path)\n",
    "\n",
    "csv_path = 'songs_features.csv'\n",
    "\n",
    "try:\n",
    "    with open(csv_path, 'w') as file:\n",
    "        file.truncate(0)\n",
    "    print(f\"Файл '{csv_path}' очищен успешно.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при очистке файла '{csv_path}': {e}\")\n",
    "\n",
    "# Создание датафрейма из полученных данных\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Вывод датафрейма\n",
    "print(df)\n",
    "csv_path = 'songs_features.csv'\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'spectrum_feature_mean', 'spectrum_feature_var',\n",
       "       'db_spectrum_feature_mean', 'db_spectrum_feature_var',\n",
       "       'melspectrum_feature_mean', 'melspectrum_feature_var',\n",
       "       'db_melspectrum_feature_mean', 'db_melspectrum_feature_var',\n",
       "       'spectral_cent_feature_mean', 'spectral_cent_feature_var',\n",
       "       'spectral_rolloff_feature_mean', 'spectral_rolloff_feature_var',\n",
       "       'zero_crossing_feature_mean', 'zero_crossing_feature_var'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка дискретизированного аудиофайла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл 'songs_features.csv' очищен успешно.\n",
      "                                        filename  spectrum_mean  spectrum_var  \\\n",
      "0    7 Seconds -- Youssou N'Dour, Neneh Cherry_1       0.009078      0.001058   \n",
      "1    7 Seconds -- Youssou N'Dour, Neneh Cherry_2       1.532228     26.641769   \n",
      "2    7 Seconds -- Youssou N'Dour, Neneh Cherry_3       1.652172     30.376503   \n",
      "3    7 Seconds -- Youssou N'Dour, Neneh Cherry_4       2.186472     34.958107   \n",
      "4    7 Seconds -- Youssou N'Dour, Neneh Cherry_5       2.133529     49.443848   \n",
      "..                                           ...            ...           ...   \n",
      "204             Bag Raiders -- Shooting stars_10       2.832639     34.444614   \n",
      "205             Bag Raiders -- Shooting stars_11       5.193159     94.942253   \n",
      "206             Bag Raiders -- Shooting stars_12       6.934866    129.035187   \n",
      "207             Bag Raiders -- Shooting stars_13       8.448624    131.645828   \n",
      "208             Bag Raiders -- Shooting stars_14       6.249237    170.268631   \n",
      "\n",
      "     db_spectrum_mean  db_spectrum_var  melspectrum_mean  melspectrum_var  \\\n",
      "0          -12.812612       205.178406         -0.953486      1314.747803   \n",
      "1           -9.500680       173.792084          0.969639       761.384155   \n",
      "2           -7.271348       160.399948          1.154840       620.613342   \n",
      "3           -7.141399       152.403412          1.158778       624.192322   \n",
      "4           -7.339091       161.141342          1.168531       637.773987   \n",
      "..                ...              ...               ...              ...   \n",
      "204          0.509413       218.083649          0.477826       444.284882   \n",
      "205          4.371059       139.435562          1.859574       250.618271   \n",
      "206          4.598207       137.685516          1.789106       250.959274   \n",
      "207          4.741551       137.243576          1.843002       250.833588   \n",
      "208          1.696471       141.551300         -0.571229       252.113113   \n",
      "\n",
      "     db_melspectrum_mean  db_melspectrum_var  spectral_cent_mean  \\\n",
      "0             -40.543999          220.348526         2167.678790   \n",
      "1             -36.075829          139.585419         2144.373441   \n",
      "2             -33.708900          132.446091         2321.568723   \n",
      "3             -34.302139          131.703003         2336.895541   \n",
      "4             -33.914413          138.742401         2315.242448   \n",
      "..                   ...                 ...                 ...   \n",
      "204           -29.923891          139.882767         2780.865815   \n",
      "205           -26.931646           76.902145         2933.494685   \n",
      "206           -26.646225           75.898376         2945.812628   \n",
      "207           -26.098217           74.793228         2959.645461   \n",
      "208           -29.861080           77.952583         3078.354124   \n",
      "\n",
      "     spectral_cent_var  spectral_rolloff_mean  spectral_rolloff_var  \\\n",
      "0        934130.593848            4809.514064          3.996404e+06   \n",
      "1        875787.463924            4996.490011          4.303563e+06   \n",
      "2        858806.020645            5360.568513          3.887818e+06   \n",
      "3        924012.630552            5490.554618          4.275509e+06   \n",
      "4        845211.849772            5406.345305          4.248520e+06   \n",
      "..                 ...                    ...                   ...   \n",
      "204      604216.640687            5854.970358          1.789158e+06   \n",
      "205      601846.168261            6331.873352          1.109915e+06   \n",
      "206      562777.394191            6363.498682          1.021491e+06   \n",
      "207      583882.516817            6376.588472          1.024318e+06   \n",
      "208      281354.557323            6671.520911          6.958827e+05   \n",
      "\n",
      "     zero_crossing_mean  zero_crossing_var  \n",
      "0              0.078791           0.007335  \n",
      "1              0.061576           0.001978  \n",
      "2              0.072787           0.002232  \n",
      "3              0.072949           0.002300  \n",
      "4              0.074253           0.001858  \n",
      "..                  ...                ...  \n",
      "204            0.132829           0.005739  \n",
      "205            0.138407           0.005995  \n",
      "206            0.136907           0.005331  \n",
      "207            0.139011           0.005741  \n",
      "208            0.141534           0.002260  \n",
      "\n",
      "[209 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy.stats import moment\n",
    "\n",
    "n_fft = 8195\n",
    "sr = 22050\n",
    "hop_length = n_fft // 2\n",
    "segment_duration = 20  # Длительность каждого сегмента в секундах\n",
    "segment_samples = segment_duration * sr  # Количество отсчетов в каждом сегменте\n",
    "\n",
    "def segment_audio(signal, sr, segment_duration, overlap):\n",
    "    # Разбиваем аудиозапись на сегменты по segment_duration секунд с перекрытием overlap\n",
    "    segments = []\n",
    "    start = 0\n",
    "    while start + segment_duration <= len(signal) / sr:\n",
    "        segment = signal[int(start * sr): int((start + segment_duration) * sr)]\n",
    "        # Если сегмент короче ожидаемой длительности, дополним его нулями\n",
    "        if len(segment) < segment_duration * sr:\n",
    "            segment = np.concatenate([segment, np.zeros(segment_duration * sr - len(segment))])\n",
    "        segments.append(segment)\n",
    "        start += overlap\n",
    "    return segments\n",
    "\n",
    "def extract_features(signal):\n",
    "    features = {}\n",
    "    features['spectrum_mean'], features['spectrum_var'] = spectrum_feature(signal)\n",
    "    features['db_spectrum_mean'], features['db_spectrum_var'] = db_spectrum_feature(signal)\n",
    "    features['melspectrum_mean'], features['melspectrum_var'] = melspectrum_feature(signal)\n",
    "    features['db_melspectrum_mean'], features['db_melspectrum_var'] = db_melspectrum_feature(signal)\n",
    "    features['spectral_cent_mean'], features['spectral_cent_var'] = spectral_cent_feature(signal)\n",
    "    features['spectral_rolloff_mean'], features['spectral_rolloff_var'] = spectral_rolloff_feature(signal)\n",
    "    features['zero_crossing_mean'], features['zero_crossing_var'] = zero_crossing_feature(signal)\n",
    "    return features\n",
    "\n",
    "\n",
    "csv_path = 'songs_features.csv'\n",
    "\n",
    "try:\n",
    "    with open(csv_path, 'w') as file:\n",
    "        file.truncate(0)\n",
    "    print(f\"Файл '{csv_path}' очищен успешно.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при очистке файла '{csv_path}': {e}\")\n",
    "\n",
    "# Путь к папке с аудиокомпозициями\n",
    "songs_dir = 'songs/'\n",
    "\n",
    "# Список имен файлов в папке songs\n",
    "file_names = os.listdir(songs_dir)\n",
    "\n",
    "# Создание пустого списка для хранения словарей признаков\n",
    "segments_data = []\n",
    "\n",
    "# Добавление признаков в DataFrame для каждого сегмента каждой композиции\n",
    "\n",
    "for filename in file_names:\n",
    "    file_path = os.path.join(songs_dir, filename)\n",
    "    signal, sr = librosa.load(file_path, sr=sr)\n",
    "    segments = segment_audio(signal, sr, segment_duration, segment_duration - 5)  # Изменение с перекрытием\n",
    "    for i, segment in enumerate(segments):\n",
    "        # Обрезаем тишину в начале и в конце сегмента\n",
    "        segment, _ = librosa.effects.trim(segment) # эта строка убирается, если тишину необходимо оставить\n",
    "        features = extract_features(segment)\n",
    "        segment_data = {'filename': f\"{filename[:-4]}_{i+1}\", **features}\n",
    "        segments_data.append(segment_data)\n",
    "\n",
    "# Создание DataFrame из списка словарей\n",
    "df = pd.DataFrame(segments_data)\n",
    "\n",
    "# Вывод DataFrame\n",
    "print(df)\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    spectrum_feature_mean  spectrum_feature_var  db_spectrum_feature_mean  \\\n",
      "0            1.415024e-03          5.448380e-06                 -8.287863   \n",
      "1            8.429581e-04          8.048017e-06                 -3.834793   \n",
      "2            7.433493e-20          1.894931e-39                 -7.576152   \n",
      "3            8.187937e-06          3.205970e-11                 -6.590091   \n",
      "4            6.735864e-02          2.151134e-01                 -2.964818   \n",
      "5            1.317450e+00          2.668646e+00                 -5.605087   \n",
      "6            2.534112e+00          8.626266e+01                 -9.704225   \n",
      "7            5.115468e-01          5.532359e+00                 -6.469716   \n",
      "8            1.043127e+00          3.236451e+01                -14.959120   \n",
      "9            1.066156e-01          1.368918e-01                 -2.647291   \n",
      "10           1.173418e+00          1.380086e+01                 -1.725452   \n",
      "11           1.118220e-01          5.227377e-02                 -5.999099   \n",
      "12           1.257828e+00          1.306695e+01                  0.159999   \n",
      "13           0.000000e+00          0.000000e+00                 -4.564194   \n",
      "\n",
      "    db_spectrum_feature_var  melspectrum_feature_mean  \\\n",
      "0                 183.82559                  0.491729   \n",
      "1                 194.87955                  0.673672   \n",
      "2                 227.38058                 -0.239590   \n",
      "3                 223.91661                 -1.433796   \n",
      "4                 232.94814                  0.999311   \n",
      "5                 199.45609                  1.684261   \n",
      "6                 244.72223                 -0.118737   \n",
      "7                 202.54707                  2.375242   \n",
      "8                 176.02852                  0.299069   \n",
      "9                 210.30705                  1.562078   \n",
      "10                174.92451                  2.387646   \n",
      "11                170.62897                 -0.654117   \n",
      "12                156.04608                  2.683933   \n",
      "13                241.65074                  0.056305   \n",
      "\n",
      "    melspectrum_feature_var  db_melspectrum_feature_mean  \\\n",
      "0                 855.34546                   -36.724155   \n",
      "1                 573.95710                   -32.740540   \n",
      "2                 775.82390                   -35.064697   \n",
      "3                 730.50740                   -37.533047   \n",
      "4                 696.54380                   -33.704384   \n",
      "5                 699.96844                   -38.956963   \n",
      "6                1229.66850                   -42.245285   \n",
      "7                 822.80493                   -40.796760   \n",
      "8                1672.33090                   -46.682167   \n",
      "9                 599.01450                   -32.549515   \n",
      "10                466.66190                   -34.194695   \n",
      "11                598.95660                   -32.485855   \n",
      "12                381.05606                   -33.769634   \n",
      "13                789.33673                   -36.771465   \n",
      "\n",
      "    db_melspectrum_feature_var  spectral_cent_feature_mean  \\\n",
      "0                    188.00389                 2356.448979   \n",
      "1                    150.70802                 3066.568414   \n",
      "2                    189.55287                 2317.971521   \n",
      "3                    184.29701                 2604.661680   \n",
      "4                    208.66330                 2585.741349   \n",
      "5                    175.07474                 2361.815105   \n",
      "6                    273.59880                 2321.758114   \n",
      "7                    220.41610                 2320.404901   \n",
      "8                    243.73723                 1982.151405   \n",
      "9                    185.37115                 2377.655256   \n",
      "10                   139.69675                 2788.655576   \n",
      "11                   130.90929                 2805.155589   \n",
      "12                   122.69594                 2654.138657   \n",
      "13                   225.27774                 2568.825410   \n",
      "\n",
      "    spectral_cent_feature_var  spectral_rolloff_feature_mean  \\\n",
      "0                8.056417e+05                    5451.249982   \n",
      "1                4.997095e+05                    6386.644779   \n",
      "2                5.345223e+05                    4717.916775   \n",
      "3                6.035786e+05                    5313.938028   \n",
      "4                7.094762e+05                    5394.788964   \n",
      "5                9.266412e+05                    5285.064926   \n",
      "6                1.137839e+06                    4624.239065   \n",
      "7                1.275571e+06                    5045.999115   \n",
      "8                1.193900e+06                    4267.311916   \n",
      "9                6.180855e+05                    4893.505219   \n",
      "10               8.625495e+05                    5834.945537   \n",
      "11               4.596756e+05                    6007.151149   \n",
      "12               3.280349e+05                    5848.060779   \n",
      "13               1.093259e+06                    5401.030769   \n",
      "\n",
      "    spectral_rolloff_feature_var  zero_crossing_feature_mean  \\\n",
      "0                   3.849403e+06                    0.081876   \n",
      "1                   1.307466e+06                    0.157460   \n",
      "2                   1.967330e+06                    0.113427   \n",
      "3                   2.260727e+06                    0.132902   \n",
      "4                   3.399842e+06                    0.121702   \n",
      "5                   4.940888e+06                    0.076777   \n",
      "6                   4.387045e+06                    0.114768   \n",
      "7                   5.746121e+06                    0.094152   \n",
      "8                   5.235771e+06                    0.062945   \n",
      "9                   2.646404e+06                    0.110291   \n",
      "10                  3.108903e+06                    0.125001   \n",
      "11                  1.882717e+06                    0.125633   \n",
      "12                  1.325791e+06                    0.102773   \n",
      "13                  3.437602e+06                    0.124630   \n",
      "\n",
      "    zero_crossing_feature_var  \n",
      "0                    0.002758  \n",
      "1                    0.004605  \n",
      "2                    0.003524  \n",
      "3                    0.004109  \n",
      "4                    0.002971  \n",
      "5                    0.005065  \n",
      "6                    0.006871  \n",
      "7                    0.004737  \n",
      "8                    0.003571  \n",
      "9                    0.002982  \n",
      "10                   0.005539  \n",
      "11                   0.003313  \n",
      "12                   0.002132  \n",
      "13                   0.008148  \n",
      "Features:\n",
      "[[ 7.47407079e-01  1.84110832e+01 -6.43032694e+00  2.03364059e+02\n",
      "   2.56333947e+00  7.91432434e+02 -3.96839180e+01  2.15656616e+02\n",
      "   2.26788371e+03  1.19863457e+06  4.96018372e+03  5.62950714e+06\n",
      "   9.03437396e-02  4.40387526e-03]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('songs_features.csv')\n",
    "filename_new = 'test_data/Timbaland_-_Apologize_47972715.mp3'\n",
    "signal = librosa.load(filename_new, sr=22050)[0] #, duration=20\n",
    "spectrum_mean, spectrum_var = spectrum_feature(signal)\n",
    "db_spectrum_mean, db_spectrum_var = db_spectrum_feature(signal)\n",
    "melspectrum_mean, melspectrum_var = melspectrum_feature(signal)\n",
    "db_melspectrum_mean, db_melspectrum_var = db_melspectrum_feature(signal)\n",
    "spectral_cent_mean, spectral_cent_var = spectral_cent_feature(signal)\n",
    "spectral_rolloff_mean, spectral_rolloff_var = spectral_rolloff_feature(signal)\n",
    "zero_crossing_mean, zero_crossing_var = zero_crossing_feature(signal)\n",
    "\n",
    "new_features = [spectrum_mean, spectrum_var, db_spectrum_mean, db_spectrum_var, melspectrum_mean, melspectrum_var, db_melspectrum_mean, db_melspectrum_var, spectral_cent_mean, spectral_cent_var, spectral_rolloff_mean, spectral_rolloff_var, zero_crossing_mean, zero_crossing_var]\n",
    "new_features = np.array(new_features).reshape(1, -1)\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop(columns=['filename'])\n",
    "print(X)\n",
    "print('Features:')\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки новой композиции:\n",
      "[[ 7.47407079e-01  1.84110832e+01 -6.43032694e+00  2.03364059e+02\n",
      "   2.56333947e+00  7.91432434e+02 -3.96839180e+01  2.15656616e+02\n",
      "   2.26788371e+03  1.19863457e+06  4.96018372e+03  5.62950714e+06\n",
      "   9.03437396e-02  4.40387526e-03]]\n",
      "\n",
      "Другие похожие файлы и их признаки:\n",
      "\n",
      "Файл 1: Apologize.mp3\n",
      "[ 5.11546850e-01  5.53235860e+00 -6.46971560e+00  2.02547070e+02\n",
      "  2.37524150e+00  8.22804930e+02 -4.07967600e+01  2.20416100e+02\n",
      "  2.32040490e+03  1.27557061e+06  5.04599911e+03  5.74612117e+06\n",
      "  9.41517279e-02  4.73722360e-03]\n",
      "Расстояние: 139706.8267316446\n",
      "\n",
      "Файл 2: Appletree.mp3\n",
      "[ 1.04312700e+00  3.23645060e+01 -1.49591200e+01  1.76028520e+02\n",
      "  2.99068900e-01  1.67233090e+03 -4.66821670e+01  2.43737230e+02\n",
      "  1.98215141e+03  1.19390030e+06  4.26731192e+03  5.23577064e+06\n",
      "  6.29451775e-02  3.57126172e-03]\n",
      "Расстояние: 393766.6620908847\n",
      "\n",
      "Файл 3: Animals — Martin Garrix.mp3\n",
      "[ 1.31745000e+00  2.66864560e+00 -5.60508730e+00  1.99456090e+02\n",
      "  1.68426120e+00  6.99968440e+02 -3.89569630e+01  1.75074740e+02\n",
      "  2.36181510e+03  9.26641206e+05  5.28506493e+03  4.94088763e+06\n",
      "  7.67766613e-02  5.06472248e-03]\n",
      "Расстояние: 740389.9917819516\n",
      "\n",
      "Файл 4: Another One Bites The Dust — Queen.mp3\n",
      "[ 2.53411200e+00  8.62626650e+01 -9.70422500e+00  2.44722230e+02\n",
      " -1.18737094e-01  1.22966850e+03 -4.22452850e+01  2.73598800e+02\n",
      "  2.32175811e+03  1.13783929e+06  4.62423907e+03  4.38704451e+06\n",
      "  1.14768490e-01  6.87091943e-03]\n",
      "Расстояние: 1243949.2669466168\n",
      "\n",
      "Файл 5: 7 Seconds -- Youssou N'Dour, Neneh Cherry.mp3\n",
      "[ 1.41502430e-03  5.44838000e-06 -8.28786300e+00  1.83825590e+02\n",
      "  4.91729350e-01  8.55345460e+02 -3.67241550e+01  1.88003890e+02\n",
      "  2.35644898e+03  8.05641701e+05  5.45124998e+03  3.84940342e+06\n",
      "  8.18757816e-02  2.75802819e-03]\n",
      "Расстояние: 1822968.1622610097\n",
      "\n",
      "Файл 6: Bag Raiders -- Shooting stars.mp3\n",
      "[ 0.00000000e+00  0.00000000e+00 -4.56419400e+00  2.41650740e+02\n",
      "  5.63046600e-02  7.89336730e+02 -3.67714650e+01  2.25277740e+02\n",
      "  2.56882541e+03  1.09325901e+06  5.40103077e+03  3.43760192e+06\n",
      "  1.24630468e-01  8.14783443e-03]\n",
      "Расстояние: 2194436.787620201\n",
      "\n",
      "Файл 7: All The Things She Said.mp3\n",
      "[ 6.73586350e-02  2.15113360e-01 -2.96481820e+00  2.32948140e+02\n",
      "  9.99311030e-01  6.96543800e+02 -3.37043840e+01  2.08663300e+02\n",
      "  2.58574135e+03  7.09476206e+05  5.39478896e+03  3.39984223e+06\n",
      "  1.21702251e-01  2.97111885e-03]\n",
      "Расстояние: 2282691.793995697\n",
      "\n",
      "Файл 8: B.o.B, Jessie J -- Price Tag.mp3\n",
      "[ 1.17341760e+00  1.38008630e+01 -1.72545160e+00  1.74924510e+02\n",
      "  2.38764600e+00  4.66661900e+02 -3.41946950e+01  1.39696750e+02\n",
      "  2.78865558e+03  8.62549464e+05  5.83494554e+03  3.10890300e+06\n",
      "  1.25000512e-01  5.53897561e-03]\n",
      "Расстояние: 2542911.6339464523\n",
      "\n",
      "Файл 9: B.o.B, Hayley Williams of Paramore -- Airplanes (feat. Hayley Williams of Paramore).mp3\n",
      "[ 1.06615630e-01  1.36891750e-01 -2.64729100e+00  2.10307050e+02\n",
      "  1.56207750e+00  5.99014500e+02 -3.25495150e+01  1.85371150e+02\n",
      "  2.37765526e+03  6.18085467e+05  4.89350522e+03  2.64640402e+06\n",
      "  1.10291032e-01  2.98224368e-03]\n",
      "Расстояние: 3039069.188536019\n",
      "\n",
      "Файл 10: ABBA -- The Winner Takes It All.mp3\n",
      "[ 8.18793700e-06  3.20597020e-11 -6.59009100e+00  2.23916610e+02\n",
      " -1.43379650e+00  7.30507400e+02 -3.75330470e+01  1.84297010e+02\n",
      "  2.60466168e+03  6.03578594e+05  5.31393803e+03  2.26072703e+06\n",
      "  1.32901617e-01  4.10887173e-03]\n",
      "Расстояние: 3420931.3471559966\n",
      "\n",
      "Файл 11: ABBA -- Money, Money, Money.mp3\n",
      "[ 7.43349300e-20  1.89493100e-39 -7.57615200e+00  2.27380580e+02\n",
      " -2.39590170e-01  7.75823900e+02 -3.50646970e+01  1.89552870e+02\n",
      "  2.31797152e+03  5.34522254e+05  4.71791677e+03  1.96732967e+06\n",
      "  1.13426672e-01  3.52438139e-03]\n",
      "Расстояние: 3721906.6390932575\n"
     ]
    }
   ],
   "source": [
    "# Вычислите расстояния между наборами признаков\n",
    "distances = np.linalg.norm(X.values - new_features, axis=1)\n",
    "\n",
    "# Найдите индексы строк с минимальными расстояниями (включая самый близкий)\n",
    "closest_indices = np.argsort(distances)[:11]  # Выбираем первые четыре индекса с наименьшими расстояниями\n",
    "\n",
    "# Получите названия файлов из найденных строк\n",
    "closest_files = df.iloc[closest_indices]['filename']\n",
    "\n",
    "# Получите признаки из найденных строк\n",
    "closest_features = X.iloc[closest_indices].values\n",
    "\n",
    "print(\"Признаки новой композиции:\")\n",
    "print(new_features)\n",
    "\n",
    "print(\"\\nДругие похожие файлы и их признаки:\")\n",
    "for i in range(len(closest_indices)):\n",
    "    print(f\"\\nФайл {i+1}: {closest_files.iloc[i]}\")\n",
    "    print(closest_features[i])\n",
    "    print(\"Расстояние:\", distances[closest_indices[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее похожие композиции:\n",
      "Apologize, Сумма расстояний: 401798842.77883863\n",
      "B.o.B, Hayley Williams of Paramore -- Airplanes (feat. Hayley Williams of Paramore), Сумма расстояний: 401798842.77883863\n",
      "ABBA -- Money, Money, Money, Сумма расстояний: 438326010.3041876\n",
      "All The Things She Said, Сумма расстояний: 474853177.82953656\n",
      "Another One Bites The Dust — Queen, Сумма расстояний: 474853177.82953656\n",
      "Bad Bad Boys, Сумма расстояний: 474853177.82953656\n",
      "a-ha -- Take On Me, Сумма расстояний: 511380345.3548855\n",
      "B.o.B, Jessie J -- Price Tag, Сумма расстояний: 511380345.3548855\n",
      "Bag Raiders -- Shooting stars, Сумма расстояний: 511380345.3548855\n",
      "Appletree, Сумма расстояний: 620961847.9309325\n",
      "ABBA -- The Winner Takes It All, Сумма расстояний: 694016182.9816306\n"
     ]
    }
   ],
   "source": [
    "# Создайте словарь для хранения сумм расстояний по композициям\n",
    "sum_distances = {}\n",
    "\n",
    "# Проход по каждой строке DataFrame X (признаки каждого фрагмента)\n",
    "for index, row in df.iterrows():\n",
    "    # Преобразуйте индекс в строку и получите название композиции из индекса строки\n",
    "    composition_name = row['filename'].split('_')[0]\n",
    "    \n",
    "    # Если композиция еще не добавлена в словарь, добавьте ее\n",
    "    if composition_name not in sum_distances:\n",
    "        sum_distances[composition_name] = 0\n",
    "    \n",
    "    # Вычислите расстояние между текущим фрагментом и новой композицией\n",
    "    distance = np.linalg.norm(X.values - new_features)\n",
    "    \n",
    "    # Добавьте расстояние к сумме расстояний для данной композиции\n",
    "    sum_distances[composition_name] += distance\n",
    "\n",
    "# Преобразуйте словарь в DataFrame для удобства обработки\n",
    "sum_distances_df = pd.DataFrame(list(sum_distances.items()), columns=['Composition', 'Sum Distance'])\n",
    "\n",
    "# Найдите наиболее похожие композиции на основе сумм расстояний\n",
    "closest_compositions = sum_distances_df.nsmallest(11, 'Sum Distance')\n",
    "\n",
    "# Выведите результаты\n",
    "print(\"Наиболее похожие композиции:\")\n",
    "for index, row in closest_compositions.iterrows():\n",
    "    print(f\"{row['Composition']}, Сумма расстояний: {row['Sum Distance']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки новой композиции:\n",
      "[[-2.79062164e+02  9.81874771e+01  1.55698334e+02  5.44654579e+01\n",
      "   1.57122917e+01  3.68546371e+01  3.23547440e+01  3.17071018e+01\n",
      "   7.65785456e+00  1.68530464e+01  1.50993824e+01  1.59104233e+01\n",
      "   4.79303741e+00  1.04169302e+01  5.60571718e+00  1.47617292e+01\n",
      "   1.71552563e+00  1.23163395e+01 -9.36045706e-01  1.00283155e+01\n",
      "  -1.95086256e-01  8.04045963e+00 -1.35133984e-02  7.22135305e+00\n",
      "   4.10704470e+00  6.39779472e+00]]\n",
      "\n",
      "Другие похожие файлы и их признаки:\n",
      "\n",
      "Файл 1: Appletree_4\n",
      "[-248.38965     84.76933    122.98244     35.87223     14.906594\n",
      "   36.474186    53.738476    24.243736     8.060009    24.665209\n",
      "   20.290806    18.969952    -9.005632    18.11949      7.1829386\n",
      "   13.994774    -0.647049    11.630134    -2.3296106   12.699757\n",
      "    5.143558    12.444908     1.7114475   10.630182     1.666215\n",
      "   10.089953 ]\n",
      "Расстояние: 59.14537974782552\n",
      "\n",
      "Файл 2: Appletree_3\n",
      "[-257.85806      83.774315    112.55922      38.80696      16.265879\n",
      "   33.167545     55.397232     25.364466      5.0840125    24.450838\n",
      "   18.714449     19.114191     -9.631435     18.102613      5.4648623\n",
      "   14.890049     -4.3870854    12.289606     -3.0227454    12.395545\n",
      "    4.1115756    12.046836      0.75986695   11.315282      1.8682594\n",
      "   10.449206  ]\n",
      "Расстояние: 61.83890562039747\n",
      "\n",
      "Файл 3: ABBA -- Money, Money, Money_1\n",
      "[-256.02362      94.29098     137.69928      32.317284    -30.330719\n",
      "   25.52944      28.779905     19.777935     -1.6967851    16.236197\n",
      "   12.646498     21.191402      1.030597     17.976004      2.2495549\n",
      "   14.241533      4.424231     11.770057     -0.58545786   11.847206\n",
      "   -1.656704     11.397015     -3.0537453     9.583035      3.7163763\n",
      "    9.363631  ]\n",
      "Расстояние: 63.37690635077423\n",
      "\n",
      "Файл 4: Appletree_2\n",
      "[-2.6721860e+02  7.9562070e+01  1.0925862e+02  3.6863773e+01\n",
      "  1.8929320e+01  3.0513310e+01  5.5130177e+01  2.5275312e+01\n",
      "  3.6073170e+00  2.3499758e+01  1.7241726e+01  1.8084072e+01\n",
      " -1.0129984e+01  1.7758762e+01  3.7465744e+00  1.4661888e+01\n",
      " -8.6250740e+00  1.2860076e+01 -4.7782650e+00  1.2739777e+01\n",
      "  2.1870544e+00  1.2742041e+01 -1.3343787e-01  1.2777793e+01\n",
      "  2.9049702e+00  1.1405151e+01]\n",
      "Расстояние: 64.25560168990759\n",
      "\n",
      "Файл 5: Appletree_6\n",
      "[-233.96304     78.31423    130.98456     36.425934     8.133949\n",
      "   37.546574    51.366367    23.614176    10.922993    24.850777\n",
      "   22.400356    17.470999    -8.565185    17.686062     8.557675\n",
      "   12.004619     3.3371894   10.837724    -1.1960248   11.971517\n",
      "    6.3295455   11.189363     2.8148901    9.198903     1.2819114\n",
      "    9.273985 ]\n",
      "Расстояние: 65.70534524098899\n",
      "\n",
      "Файл 6: Appletree_5\n",
      "[-231.4659       80.922295    130.46155      35.990726      7.0157065\n",
      "   37.1707       50.485504     24.484642     10.11616      24.943846\n",
      "   22.421621     17.426842     -8.815787     18.579767      9.276057\n",
      "   12.923063      1.9258355    10.929484     -1.0679367    12.566726\n",
      "    6.9722304    11.479499      2.1270177     9.755404      0.52537555\n",
      "    9.41395   ]\n",
      "Расстояние: 67.07442593937701\n",
      "\n",
      "Файл 7: Appletree_7\n",
      "[-231.18248     76.3363     135.57071     33.917816     5.7404075\n",
      "   37.60667     50.063606    24.036346    11.8617115   25.029144\n",
      "   21.831793    17.05817     -8.982225    17.238123     7.915213\n",
      "   11.770077     3.8364744   11.546842    -1.7997239   12.235502\n",
      "    6.386862    11.082053     3.0976791    8.966873     1.0490957\n",
      "    9.104662 ]\n",
      "Расстояние: 67.41018639907428\n",
      "\n",
      "Файл 8: Apologize_3\n",
      "[-245.54085     69.71974    189.14638     37.060764    -8.391963\n",
      "   20.727297    25.749039    26.687126    16.716208    22.02327\n",
      "   25.375834    12.807736     0.8038569   12.089188    17.74909\n",
      "   11.322748    -1.2173761    9.7652       4.745882     8.79854\n",
      "    6.976481     9.949536     7.9706974    7.86942      1.6634994\n",
      "    8.007253 ]\n",
      "Расстояние: 69.60211450762802\n",
      "\n",
      "Файл 9: Appletree_8\n",
      "[-227.73157      75.522644    133.51697      35.4885        1.5165012\n",
      "   36.667095     51.34897      24.700535     13.945847     24.740364\n",
      "   21.57937      16.418266    -11.057741     17.848253      7.7730136\n",
      "   12.1748495     4.5716267    11.439851     -1.6587738    12.225605\n",
      "    6.9809756    10.804454      2.9309962     8.901439      0.58713657\n",
      "    9.107916  ]\n",
      "Расстояние: 71.96240057599482\n",
      "\n",
      "Файл 10: ABBA -- Money, Money, Money_2\n",
      "[-2.3506900e+02  8.4479256e+01  1.3878201e+02  3.0584091e+01\n",
      " -2.2852660e+01  2.1236902e+01  3.9169520e+01  2.0940365e+01\n",
      " -1.8630990e-01  1.8228040e+01  2.4067240e+01  2.0124080e+01\n",
      "  3.5569206e-01  1.8585836e+01  7.7887554e+00  1.1330204e+01\n",
      "  6.2765455e+00  1.1187876e+01  2.5116558e+00  1.0210919e+01\n",
      "  1.1893018e+00  9.8775230e+00 -3.4855947e+00  9.6429560e+00\n",
      "  3.5287814e+00  9.5334160e+00]\n",
      "Расстояние: 72.14750944249887\n",
      "\n",
      "Файл 11: Appletree_1\n",
      "[-2.84728060e+02  7.48779140e+01  1.00907320e+02  3.70710950e+01\n",
      "  2.24856640e+01  2.82205730e+01  5.48827930e+01  2.63680970e+01\n",
      "  2.14977300e-01  2.35261040e+01  1.40903420e+01  1.75765780e+01\n",
      " -1.00642185e+01  1.65554030e+01  3.55686170e-02  1.38164250e+01\n",
      " -1.21985880e+01  1.23240480e+01 -7.08944800e+00  1.22679420e+01\n",
      " -2.49305340e+00  1.34668950e+01 -2.29319880e+00  1.37312000e+01\n",
      "  2.96539970e+00  1.20629240e+01]\n",
      "Расстояние: 72.68247409147034\n"
     ]
    }
   ],
   "source": [
    "# Вычислите расстояния между наборами признаков\n",
    "distances = np.linalg.norm(X.values - new_features, axis=1)\n",
    "\n",
    "# Найдите индексы строк с минимальными расстояниями (включая самый близкий)\n",
    "closest_indices = np.argsort(distances)[:11]  # Выбираем первые четыре индекса с наименьшими расстояниями\n",
    "\n",
    "# Получите названия файлов из найденных строк\n",
    "closest_files = df.iloc[closest_indices]['filename']\n",
    "\n",
    "# Получите признаки из найденных строк\n",
    "closest_features = X.iloc[closest_indices].values\n",
    "\n",
    "print(\"Признаки новой композиции:\")\n",
    "print(new_features)\n",
    "\n",
    "print(\"\\nДругие похожие файлы и их признаки:\")\n",
    "for i in range(len(closest_indices)):\n",
    "    print(f\"\\nФайл {i+1}: {closest_files.iloc[i]}\")\n",
    "    print(closest_features[i])\n",
    "    print(\"Расстояние:\", distances[closest_indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки новой композиции:\n",
      "[[-136.94652     48.15086    133.78339     25.045727    -3.4574358\n",
      "    19.012459    52.906593    12.004604    -9.7661295   17.015518\n",
      "    45.452053    11.971169   -22.336512    13.349935    21.156645\n",
      "    10.17392     -1.8026047   10.184543    13.6172285    8.353845\n",
      "    -8.874034     8.900497    11.079862     7.5026326    1.893026\n",
      "     6.3978343]]\n",
      "\n",
      "Другие похожие файлы и их признаки:\n",
      "\n",
      "Файл 1: Bad Bad Boys_5\n",
      "[-150.28946     50.68178    122.11754     22.383467   -18.054884\n",
      "   29.379808    59.9512      17.397646   -11.749435    21.948305\n",
      "   31.130291    16.501328   -17.769829    13.568505    26.109\n",
      "   11.274147    -9.232224     9.664581    13.4331665   11.080587\n",
      "    1.7540551   10.337084     6.979301     8.990133     4.5127983\n",
      "    6.9244866]\n",
      "Косинусное сходство: 0.9875544754059715\n",
      "\n",
      "Файл 2: Bad Bad Boys_7\n",
      "[-152.31073     51.82261    117.270546    21.034023   -16.460344\n",
      "   26.94437     65.02995     15.612344   -10.527432    20.826616\n",
      "   35.888798    15.061704   -17.531574    13.650693    25.799046\n",
      "   10.128178    -7.4663095    9.386877    13.764245    10.8249\n",
      "   -1.5060654    9.102082     6.9104304    8.176932     5.874531\n",
      "    6.8255477]\n",
      "Косинусное сходство: 0.98768767205757\n",
      "\n",
      "Файл 3: Bad Bad Boys_6\n",
      "[-152.3624       51.541183    120.093254     22.017084    -16.325823\n",
      "   29.156103     62.630775     16.521675    -13.082668     20.74719\n",
      "   33.448193     16.509897    -18.148005     13.3492155    27.062178\n",
      "   11.190363     -8.081296      9.597956     13.925913     10.999638\n",
      "    0.42121434   10.303386      7.627079      8.689668      4.7816787\n",
      "    6.927334  ]\n",
      "Косинусное сходство: 0.9878091603037764\n",
      "\n",
      "Файл 4: Bad Bad Boys_8\n",
      "[-144.73773     54.428432   116.95483     20.559872   -18.466333\n",
      "   26.249882    64.21597     15.082876   -13.317735    19.835623\n",
      "   34.95861     13.376217   -16.479515    13.408932    25.846596\n",
      "   10.105277    -9.061919     9.481039    12.771562    10.47633\n",
      "   -2.1228354    9.6767845    6.563095     8.430244     4.2417355\n",
      "    8.017302 ]\n",
      "Косинусное сходство: 0.9879620149081084\n",
      "\n",
      "Файл 5: 7 Seconds -- Youssou N'Dour, Neneh Cherry_3\n",
      "[-175.85992     55.39866    142.48146     31.48512     -5.452794\n",
      "   17.106672    54.20472     12.5301      -3.9571528   14.862545\n",
      "   40.402023    14.410908    -2.3755004   14.1163      21.413586\n",
      "   10.808199    -6.299252     8.296001    11.453906     9.105299\n",
      "   -1.5905281   10.299069     8.603446     7.199819     3.2885563\n",
      "    6.551465 ]\n",
      "Косинусное сходство: 0.9883468318135928\n",
      "\n",
      "Файл 6: 7 Seconds -- Youssou N'Dour, Neneh Cherry_4\n",
      "[-168.87038     55.242714   140.69824     30.286985    -5.928559\n",
      "   17.233326    54.209587    12.936077    -5.0749135   15.076431\n",
      "   41.380413    14.45346     -5.108227    14.671167    21.21708\n",
      "   10.822771    -5.7959657    8.874786    11.101801     9.165461\n",
      "   -3.6799006   11.097007     9.589622     7.566499     2.9982753\n",
      "    6.4823823]\n",
      "Косинусное сходство: 0.9915094137515135\n",
      "\n",
      "Файл 7: 7 Seconds -- Youssou N'Dour, Neneh Cherry_5\n",
      "[-158.13608     53.203526   136.64862     29.56993     -5.854443\n",
      "   17.531874    54.95231     13.563373    -7.205549    15.979454\n",
      "   43.979256    14.146444    -8.95504     14.0604725   22.159534\n",
      "   10.639447    -4.9000335   10.028434    10.879565     9.207662\n",
      "   -6.11554     10.927433    10.907071     7.68425      2.4254735\n",
      "    6.4012675]\n",
      "Косинусное сходство: 0.9954060781155664\n",
      "\n",
      "Файл 8: 7 Seconds -- Youssou N'Dour, Neneh Cherry_6\n",
      "[-152.10997     50.976982   137.6891      27.991798    -6.558939\n",
      "   17.070705    54.554134    13.242844    -7.1077256   16.306707\n",
      "   44.074944    13.608644   -11.179025    13.975544    21.219833\n",
      "   10.8559065   -3.4399679   10.658321    10.106455     9.381256\n",
      "   -7.743368    10.849631    11.607644     7.7279334    2.5790837\n",
      "    6.4668055]\n",
      "Косинусное сходство: 0.9971531513290585\n",
      "\n",
      "Файл 9: 7 Seconds -- Youssou N'Dour, Neneh Cherry_9\n",
      "[-146.59099     46.0391     133.84698     27.81346     -2.4203367\n",
      "   16.72305     56.3352      12.984861    -9.7849455   16.984886\n",
      "   44.590626    13.036114   -12.506122    12.669678    21.385061\n",
      "    9.72157     -6.088516    10.440512    10.678084     8.918683\n",
      "   -7.2246714    9.681389    11.510114     7.3507714    1.5803244\n",
      "    6.790939 ]\n",
      "Косинусное сходство: 0.9977378543561037\n",
      "\n",
      "Файл 10: 7 Seconds -- Youssou N'Dour, Neneh Cherry_8\n",
      "[-145.8422      46.18623    134.98433     27.963745    -4.7078805\n",
      "   16.527643    56.211025    13.120522    -7.9997125   16.93889\n",
      "   45.865074    12.995517   -13.453731    12.387525    21.526459\n",
      "   10.225977    -3.9620626   11.209989    10.469986     9.279477\n",
      "   -8.617611     9.694504    11.33516      7.537587     1.8331693\n",
      "    6.456655 ]\n",
      "Косинусное сходство: 0.9982204714136893\n",
      "\n",
      "Файл 11: 7 Seconds -- Youssou N'Dour, Neneh Cherry_7\n",
      "[-146.69821     47.151436   136.16597     27.562162    -7.342241\n",
      "   16.767715    55.90908     13.349072    -8.835035    17.109411\n",
      "   46.600338    13.317838   -14.194448    12.308453    21.798326\n",
      "   10.818994    -3.5019991   11.137502    10.930451     9.425507\n",
      "   -9.515672    10.229095    11.685935     7.9983835    2.061838\n",
      "    6.3952017]\n",
      "Косинусное сходство: 0.9983909745882575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('songs_features.csv')\n",
    "filename_new = 'test_data/7 Seconds from middle small.mp3'\n",
    "result = process_audio(filename_new, 20, fragment_length=20, overlap=5)\n",
    "result = list(result[0].values())[1:]\n",
    "new_features = np.array(result).reshape(1, -1)\n",
    "\n",
    "X = df.drop(columns=['filename'])\n",
    "\n",
    "# Вычислите косинусное сходство между наборами признаков\n",
    "similarities = cosine_similarity(X, new_features)\n",
    "\n",
    "# Найдите индексы строк с максимальным косинусным сходством (включая самый близкий)\n",
    "closest_indices = np.argsort(similarities, axis=0)[-11:].flatten()\n",
    "\n",
    "# Получите названия файлов из найденных строк\n",
    "closest_files = df.iloc[closest_indices]['filename']\n",
    "\n",
    "# Получите признаки из найденных строк\n",
    "closest_features = X.iloc[closest_indices].values\n",
    "\n",
    "print(\"Признаки новой композиции:\")\n",
    "print(new_features)\n",
    "\n",
    "print(\"\\nДругие похожие файлы и их признаки:\")\n",
    "for i in range(len(closest_indices)):\n",
    "    print(f\"\\nФайл {i+1}: {closest_files.iloc[i]}\")\n",
    "    print(closest_features[i])\n",
    "    print(\"Косинусное сходство:\", similarities[closest_indices[i]][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
